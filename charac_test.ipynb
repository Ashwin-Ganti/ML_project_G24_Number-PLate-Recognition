{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNet\n",
    "from keras.layers import AveragePooling2D\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.models import model_from_json\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import glob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_paths = glob.glob(\"dataset_characters/**/*.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=4\n",
    "rows=3\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "plt.rcParams.update({\"font.size\":14})\n",
    "grid = gridspec.GridSpec(ncols=cols,nrows=rows,figure=fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(45)\n",
    "rand = np.random.randint(0,len(dataset_paths),size=(cols*rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(cols*rows):\n",
    "    fig.add_subplot(grid[i])\n",
    "    image = load_img(dataset_paths[rand[i]])\n",
    "    label = dataset_paths[rand[i]].split(os.path.sep)[-2]\n",
    "    plt.title('\"{:s}\"'.format(label))\n",
    "    plt.axis(False)\n",
    "    plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=[]\n",
    "labels=[]\n",
    "\n",
    "for image_path in dataset_paths:\n",
    "  label = image_path.split(os.path.sep)[-2]\n",
    "  image=load_img(image_path,target_size=(80,80))\n",
    "  image=img_to_array(image)\n",
    "\n",
    "  X.append(image)\n",
    "  labels.append(label)\n",
    "\n",
    "X = np.array(X,dtype=\"float16\")\n",
    "labels = np.array(labels)\n",
    "\n",
    "print(\"Find {:d} images with {:d} classes\".format(len(X),len(set(labels))))\n",
    "\n",
    "lb = LabelEncoder()\n",
    "lb.fit(labels)\n",
    "labels = lb.transform(labels)\n",
    "y = to_categorical(labels)\n",
    "\n",
    "np.save('license_character_classes.npy', lb.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainX, testX, trainY, testY) = train_test_split(X, y, test_size=0.10, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_gen = ImageDataGenerator(rotation_range=10,\n",
    "                              width_shift_range=0.1,\n",
    "                              height_shift_range=0.1,\n",
    "                              shear_range=0.1,\n",
    "                              zoom_range=0.1,\n",
    "                              fill_mode=\"nearest\"\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(lr=1e-4,decay=1e-4/25, training=False,output_shape=y.shape[1]):\n",
    "    baseModel = MobileNet(weights=\"imagenet\", \n",
    "                            include_top=False,\n",
    "                            input_tensor=Input(shape=(80, 80, 3)))\n",
    "\n",
    "    headModel = baseModel.output\n",
    "    headModel = AveragePooling2D(pool_size=(3, 3))(headModel)\n",
    "    headModel = Flatten(name=\"flatten\")(headModel)\n",
    "    headModel = Dense(128, activation=\"relu\")(headModel)\n",
    "    headModel = Dropout(0.5)(headModel)\n",
    "    headModel = Dense(output_shape, activation=\"softmax\")(headModel)\n",
    "    \n",
    "    model = Model(inputs=baseModel.input, outputs=headModel)\n",
    "    \n",
    "    if training:\n",
    "\n",
    "        for layer in baseModel.layers:\n",
    "            layer.trainable = True\n",
    "\n",
    "        optimizer = Adam(lr=lr, decay = decay)\n",
    "        model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer,metrics=[\"accuracy\"])    \n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INIT_LR = 1e-4\n",
    "EPOCHS = 30\n",
    "\n",
    "model = create_model(lr=INIT_LR, decay=INIT_LR/EPOCHS,training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "my_checkpointer = [\n",
    "                EarlyStopping(monitor='val_loss', patience=5, verbose=0),\n",
    "                ModelCheckpoint(filepath=\"License_character_recognition.h5\", verbose=1, save_weights_only=True)\n",
    "                ]\n",
    "\n",
    "result = model.fit(image_gen.flow(trainX, trainY, batch_size=BATCH_SIZE), \n",
    "                   steps_per_epoch=len(trainX) // BATCH_SIZE, \n",
    "                   validation_data=(testX, testY), \n",
    "                   validation_steps=len(testX) // BATCH_SIZE, \n",
    "                   epochs=EPOCHS, callbacks=my_checkpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(14,5))\n",
    "grid=gridspec.GridSpec(ncols=2,nrows=1,figure=fig)\n",
    "fig.add_subplot(grid[0])\n",
    "plt.plot(result.history['accuracy'], label='training accuracy')\n",
    "plt.plot(result.history['val_accuracy'], label='val accuracy')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "\n",
    "fig.add_subplot(grid[1])\n",
    "plt.plot(result.history['loss'], label='training loss')\n",
    "plt.plot(result.history['val_loss'], label='val loss')\n",
    "plt.title('Loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"MobileNets_character_recognition.json\", \"w\") as json_file:\n",
    "  json_file.write(model_json)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "420b095231a2a00faff91f824a7c4be90995b47a2b6027717f9234eb3603ef70"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
